{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "<b>&nbsp;</b>\n",
    "The main steps for this project is as follow, some details are discussed in following cells:\n",
    "1. data preprocessing/transformation\n",
    "2. create models and train with **training set**\n",
    "3. hyperparameter tuning with **dev set**\n",
    "4. evaluation\n",
    "    - select evaluation metrics\n",
    "    - select benchmark models\n",
    "    - use **cross evaluation** as there is no seperate test data given\n",
    "    - if cross evaluation is too slow, try hold out.\n",
    "5. error analysis / model selection\n",
    "    - compare accuracy between models, explain the results and select a best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "<b>&nbsp;</b>\n",
    "#### Dataset summary\n",
    "* **train.txt**: information on which two authors id shares a link, there are some incorrect edges here but its up to the model to detect them after training as theres no way we could know at this stage.\n",
    "* **nodes.json**: attributes for each author (linked by author id)\n",
    "* **dev.csv**, **dev-labels.csv**: together form similar dataset like train.txt, usually used for hyperparameter tuning / testing. (-1/1 to represent no edge/edge)\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "#### Transformation overview\n",
    "* there is no way to predict anything just from id pairs (**train.txt**) unless we let the model memorize which two author are linked but that wouldn't be a machine learning technique, a natural way to start is to create a new training set that combine this pairing information with more information (attributes from **nodes.json**), so the model can learn from this extra information instead.\n",
    "* need to combine **edge information** from train.txt with **nodes information** from nodes.json to form a training set. \n",
    "    * the same transformation need to apply in testing phase\n",
    "    * this requires us to have all author information in json (including the authors in test set), or new author information will be required\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "#### What is the table like?    \n",
    "- refer to sample-table.csv\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "#### Transformation details\n",
    "* labelling of whether there is an edge between two authors can be obtained from train.txt. Use 1 when there is an edge, -1 otherwise\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "* what features to include? (feature selection)\n",
    "    1. years between first and last publish of author 1\n",
    "    2. years between first and last publish of author 2\n",
    "    3. difference of 3 and 4 (will this contribute to multicolinearity)\n",
    "    4. number of terms shared between the two nodes \n",
    "        * (or use 1 or 0 to indicate whether both authors used a same term for each term)\n",
    "    5. number of venue shared between two nodes\n",
    "        * (or use 1 or 0 to indicate whether both authors published at a venue for each venue)\n",
    "    6. ...\n",
    "    \n",
    "<b>&nbsp;</b>\n",
    "* should we link a node to itself? (does this provide information that really similar nodes should link together)\n",
    "* should pairs that are not linked (edge=0) be included, or just include pairs that shares an edge (edge=1), will this help the model to learn better what type of combinations should not share an edge?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training model\n",
    "<b>&nbsp;</b>\n",
    "The model need to output probability of an edge being true, some models we can experiment with at the moment are (sklearn built in models):\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "1. naive bayes (multinomial/gaussian). \n",
    "    - gaussian is used to compute conditional probability when predictors are continuous.\n",
    "2. logistic regression\n",
    "3. decision trees\n",
    "4. random forest (ensemble)\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "\n",
    "some things to be aware of:\n",
    "- outputs of sklearn model, is it a probability, or just a class label that extra steps are required to find the probability.\n",
    "- is the model compatible with our attribute type (this can be something to talk about in error analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "\n",
    "#### Evaluation metrics:\n",
    "1. accuracy, precision, etc..\n",
    "2. confusion table\n",
    "3. AUC\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "#### Benchmark\n",
    "- naive\n",
    "- majority\n",
    "- decision stump\n",
    "\n",
    "<b>&nbsp;</b>\n",
    "*And finally compare results from training set (cross validation) with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
