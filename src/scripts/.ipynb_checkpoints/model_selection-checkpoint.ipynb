{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X: [[22.          2.          0.          3.         12.          0.46153846\n",
      "   3.          0.375       0.          0.        ]\n",
      " [14.          0.          1.          5.         13.          0.56521739\n",
      "   2.          0.33333333  0.          0.        ]]\n",
      "Training set Y: [1 1]\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('../data/final/train_reconstructed.csv')\n",
    "\n",
    "X_train = train_set.iloc[:,:-1].values\n",
    "y_train = train_set['edge'].values\n",
    "\n",
    "print('Training set X: {}'.format(X_train[:2]))\n",
    "print('Training set Y: {}'.format(y_train[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set X: [[ 9.          0.          1.          2.          6.          0.3\n",
      "   0.          0.          0.          0.        ]\n",
      " [12.          0.          0.          2.          8.          0.34782609\n",
      "   1.          0.14285714  0.          0.        ]]\n",
      "Test set Y: [0 1]\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_csv('../data/final/dev-test.csv')\n",
    "\n",
    "X_test = test_set.iloc[:,:-1].values\n",
    "y_test = test_set['edge'].values\n",
    "\n",
    "print('Test set X: {}'.format(X_test[:2]))\n",
    "print('Test set Y: {}'.format(y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy for train set: 0.5011504396885933\n",
      "Accuracy for dev set: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "ds_clf = DummyClassifier(strategy=\"most_frequent\") # Define our model, set parameter strategy to 'most_frequent'\n",
    "ds_clf.fit(X_train, y_train) # Use model.fit to train with our dataset \n",
    "Y_predict = ds_clf.predict(X_test) # Use model.predict to make prediction\n",
    "print(\"Prediction :\", Y_predict[:10])\n",
    "print(\"Accuracy for train set:\", ds_clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set:\", ds_clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:0.10, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.20, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.30, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.40, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.50, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.60, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.70, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.80, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:0.90, acc_train:0.9599, acc_test:0.7641\n",
      "alpha:1.00, acc_train:0.9599, acc_test:0.7641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "bnb_train_results = []\n",
    "bnb_test_results = []\n",
    "\n",
    "for a in alpha:\n",
    "    bnb = BernoulliNB(alpha=a)\n",
    "    bnb.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = bnb.score(X_train, y_train)\n",
    "    test_acc = bnb.score(X_test, y_test)\n",
    "    \n",
    "    print(\"alpha:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}\".format(a, train_acc, test_acc))\n",
    "    bnb_train_results.append(train_acc)\n",
    "    bnb_test_results.append(test_acc)\n",
    "    \n",
    "    # Prob of being one\n",
    "    Y_train_proba = bnb.predict_proba(X_test)\n",
    "    #print(\"Probabilities :\", Y_proba[:10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF : depth:0.10, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.20, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.30, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.40, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.50, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.60, acc_train:0.9071, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.70, acc_train:0.9070, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.80, acc_train:0.9070, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:0.90, acc_train:0.9070, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n",
      "RF : depth:1.00, acc_train:0.9070, acc_test:0.6745, AUC_train:0.9632, AUC_test:0.7647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "mnb_train_results_acc = []\n",
    "mnb_test_results_acc = []\n",
    "mnb_train_results_auc = []\n",
    "mnb_test_results_auc = []\n",
    "\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(alpha=a)\n",
    "    mnb.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = mnb.score(X_train, y_train)\n",
    "    test_acc = mnb.score(X_test, y_test)\n",
    "    \n",
    "    # Prob of edge=1\n",
    "    y_train_proba = mnb.predict_proba(X_train)\n",
    "    y_test_proba = mnb.predict_proba(X_test)\n",
    "    \n",
    "    # get roc fpr and tpr\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "    auc_train = metrics.auc(fpr, tpr)\n",
    "    auc_test = metrics.auc(fpr1, tpr1)\n",
    "    print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                                                    train_acc, \n",
    "                                                                                                    test_acc,\n",
    "                                                                                                    auc_train,\n",
    "                                                                                                    auc_test))                 \n",
    "\n",
    "    mnb_train_results_acc.append(train_acc)\n",
    "    mnb_test_results_acc.append(test_acc)\n",
    "    mnb_train_results_auc.append(auc_train)\n",
    "    mnb_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB: acc_train:0.9515, acc_test:0.7877, AUC_train:0.9851, AUC_test:0.8111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_train_results_acc = []\n",
    "gnb_test_results_acc = []\n",
    "gnb_train_results_auc = []\n",
    "gnb_test_results_auc = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "train_acc = gnb.score(X_train, y_train)\n",
    "test_acc = gnb.score(X_test, y_test)\n",
    "\n",
    "# Prob of edge=1\n",
    "y_train_proba = gnb.predict_proba(X_train)\n",
    "y_test_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "auc_train = metrics.auc(fpr, tpr)\n",
    "auc_test = metrics.auc(fpr1, tpr1)\n",
    "print(\"GNB: acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(train_acc, \n",
    "                                                                                         test_acc,\n",
    "                                                                                         auc_train,\n",
    "                                                                                         auc_test))                 \n",
    "\n",
    "gnb_train_results_acc.append(train_acc)\n",
    "gnb_test_results_acc.append(test_acc)\n",
    "gnb_train_results_auc.append(auc_train)\n",
    "gnb_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF : depth:1.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9801, AUC_test:0.8254\n",
      "RF : depth:2.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9864, AUC_test:0.8305\n",
      "RF : depth:3.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9892, AUC_test:0.8329\n",
      "RF : depth:4.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9900, AUC_test:0.8291\n",
      "RF : depth:5.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9909, AUC_test:0.8368\n",
      "RF : depth:6.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9919, AUC_test:0.8371\n",
      "RF : depth:7.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9925, AUC_test:0.8388\n",
      "RF : depth:8.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9934, AUC_test:0.8376\n",
      "RF : depth:9.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9944, AUC_test:0.8379\n",
      "RF : depth:10.00, acc_train:0.9719, acc_test:0.7877, AUC_train:0.9956, AUC_test:0.8363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "depth = range(1,10+1)\n",
    "rf_train_results_acc = []\n",
    "rf_test_results_acc = []\n",
    "rf_train_results_auc = []\n",
    "rf_test_results_auc = []\n",
    "\n",
    "for d in depth:\n",
    "    rf = RandomForestClassifier(max_depth=d, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_acc = clf.score(X_train,y_train)\n",
    "    # Prob of edge=1\n",
    "    y_train_proba = rf.predict_proba(X_train)\n",
    "    y_test_proba = rf.predict_proba(X_test)\n",
    "\n",
    "    # get roc fpr and tpr\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "    auc_train = metrics.auc(fpr, tpr)\n",
    "    auc_test = metrics.auc(fpr1, tpr1)\n",
    "    print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(d, \n",
    "                                                                                                    train_acc, \n",
    "                                                                                                    test_acc,\n",
    "                                                                                                    auc_train,\n",
    "                                                                                                    auc_test))                 \n",
    "\n",
    "    rf_train_results_acc.append(train_acc)\n",
    "    rf_test_results_acc.append(test_acc)\n",
    "    rf_train_results_auc.append(auc_train)\n",
    "    rf_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR : acc_train:0.9719, acc_test:0.7877, AUC_train:0.9904, AUC_test:0.8408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_train_results_acc = []\n",
    "lr_test_results_acc = []\n",
    "lr_train_results_auc = []\n",
    "lr_test_results_auc = []\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prob of edge=1\n",
    "y_train_proba = lr.predict_proba(X_train)\n",
    "y_test_proba = lr.predict_proba(X_test)\n",
    "\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "auc_train = metrics.auc(fpr, tpr)\n",
    "auc_test = metrics.auc(fpr1, tpr1)\n",
    "print(\"LR : acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(train_acc, \n",
    "                                                                                         test_acc,\n",
    "                                                                                         auc_train,\n",
    "                                                                                         auc_test))                 \n",
    "\n",
    "lr_train_results_acc.append(train_acc)\n",
    "lr_test_results_acc.append(test_acc)\n",
    "lr_train_results_auc.append(auc_train)\n",
    "lr_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB: alpha:----, acc_train:0.9515, acc_test:0.7877, AUC_test:0.8111\n",
      "MNB: alpha:1.00, acc_train:0.9071, acc_test:0.6745, AUC_test:0.7647\n",
      "RF : depth:1.00, acc_train:0.9672, acc_test:0.7842, AUC_test:0.8380\n"
     ]
    }
   ],
   "source": [
    "# use selected model and hyperparameter to calculate evaluation metrics: AUC, Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# GNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "train_acc = gnb.score(X_train, y_train)\n",
    "test_acc = gnb.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = gnb.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "# results\n",
    "print(\"GNB: alpha:----, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(\n",
    "                                                                                train_acc, \n",
    "                                                                                test_acc,\n",
    "                                                                                metrics.auc(fpr, tpr)))\n",
    "# MNB\n",
    "mnb = MultinomialNB(alpha=0.5)\n",
    "mnb.fit(X_train, y_train)\n",
    "train_acc = mnb.score(X_train, y_train)\n",
    "test_acc = mnb.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = mnb.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "# results\n",
    "print(\"MNB: alpha:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                            train_acc, \n",
    "                                                                            test_acc,\n",
    "                                                                            metrics.auc(fpr, tpr)))\n",
    "\n",
    "# random forest\n",
    "rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "train_acc = rf.score(X_train,y_train)\n",
    "test_acc = rf.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = rf.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                                     train_acc, \n",
    "                                                                                     test_acc,\n",
    "                                                                                     metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training full model\n",
    "X_big = np.concatenate((X_train,X_test),0)\n",
    "y_big = np.concatenate((y_train,y_test),0)\n",
    "\n",
    "test_final = pd.read_csv('../data/final/test-final.csv')\n",
    "test_final = test_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,max_depth=2)\n",
    "clf.fit(X_big, y_big)\n",
    "print(\"Probabilities :\",  clf.predict_proba(test_final)[:,1])\n",
    "pred = clf.predict_proba(test_final)[:,1]\n",
    "# print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "# print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model.\n",
    "\n",
    "submission = {\n",
    "    'Id': range(1,len(pred)+1),\n",
    "    'Predicted': pred\n",
    "}\n",
    "\n",
    "submission_df = pd.DataFrame(data=submission)\n",
    "submission_df.to_csv('../data/final/sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
