{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training set X: [[ 7.         15.          7.          5.          2.          2.\n   2.          0.          0.         12.          0.46153846  3.\n   0.375       0.          0.        ]\n [ 7.          7.          7.          7.          2.          1.\n   0.          1.          0.         13.          0.56521739  2.\n   0.33333333  0.          0.        ]]\nTraining set Y: [1 1]\n"
    }
   ],
   "source": [
    "train_set = pd.read_csv('../data/final/train_reconstructed.csv')\n",
    "\n",
    "X_train = train_set.iloc[:,:-1].values\n",
    "y_train = train_set['edge'].values\n",
    "\n",
    "print('Training set X: {}'.format(X_train[:2]))\n",
    "print('Training set Y: {}'.format(y_train[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test set X: [[4.         5.         3.         3.         1.         0.\n  0.         1.         0.         6.         0.3        0.\n  0.         0.         0.        ]\n [8.         4.         2.         2.         0.         0.\n  0.         0.         0.         8.         0.34782609 1.\n  0.14285714 0.         0.        ]]\nTest set Y: [0 1]\n"
    }
   ],
   "source": [
    "test_set = pd.read_csv('../data/final/dev-test.csv')\n",
    "\n",
    "X_test = test_set.iloc[:,:-1].values\n",
    "y_test = test_set['edge'].values\n",
    "\n",
    "print('Test set X: {}'.format(X_test[:2]))\n",
    "print('Test set Y: {}'.format(y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction : [1 1 1 1 1 1 1 1 1 1]\nAccuracy for train set: 0.5012030975822467\nAccuracy for dev set: 0.5\n"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "ds_clf = DummyClassifier(strategy=\"most_frequent\") # Define our model, set parameter strategy to 'most_frequent'\n",
    "ds_clf.fit(X_train, y_train) # Use model.fit to train with our dataset \n",
    "Y_predict = ds_clf.predict(X_test) # Use model.predict to make prediction\n",
    "print(\"Prediction :\", Y_predict[:10])\n",
    "print(\"Accuracy for train set:\", ds_clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set:\", ds_clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [7.06494086e-06 1.08507418e-02 6.05664564e-03 5.90119628e-03\n 5.57597558e-01 5.57597558e-01 5.57597558e-01 5.57597558e-01\n 1.08507418e-02 2.31106212e-05]\nAccuracy for train set: 0.9594729486923538\nAccuracy for dev set:  0.7986025482942869\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "Y_proba = bnb.predict_proba(X_test) # Use model.predict to make prediction\n",
    "# Prob of being one\n",
    "print(\"Probabilities :\", Y_proba[:10,1])\n",
    "print(\"Accuracy for train set:\", bnb.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", bnb.score(X_test, y_test)) # Use model.score to evaluate our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [0.05434232 0.10237368 0.14717173 0.23653314 0.60564735 0.61282509\n 0.68590436 0.61669096 0.32421626 0.09030745]\nAccuracy for train set: 0.9613852959409904\nAccuracy for dev set:  0.8070283600493219\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 2 0.80\n",
    "clf = RandomForestClassifier(n_estimators=100,min_samples_split=10,bootstrap=False,max_leaf_nodes=5,\n",
    "    max_depth=9)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Probabilities :\",  clf.predict_proba(X_test)[:10,1])\n",
    "print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for train set: 0.9613958033434554\nAccuracy for dev set:  0.7858610768598439\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0,max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8182\nEpoch 2/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9376\nEpoch 3/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9554\nEpoch 4/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9595\nEpoch 5/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9614\nEpoch 6/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9624\nEpoch 7/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9629\nEpoch 8/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9633\nEpoch 9/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1126 - accuracy: 0.9635\nEpoch 10/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9638\nEpoch 11/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9640\nEpoch 12/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9638\nEpoch 13/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9645\nEpoch 14/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9646\nEpoch 15/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9647\nEpoch 16/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9643\nEpoch 17/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9644\nEpoch 18/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9648\nEpoch 19/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9650\nEpoch 20/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9650\nEpoch 21/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9643\nEpoch 22/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9645\nEpoch 23/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9651\nEpoch 24/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9651\nEpoch 25/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9649\nEpoch 26/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9649\nEpoch 27/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9654\nEpoch 28/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9653\nEpoch 29/30\n48/48 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9650\nEpoch 30/30\n48/48 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9650\n3/3 [==============================] - 0s 2ms/step - loss: 0.7180 - accuracy: 0.7910\nOn the test set: the loss is 0.7180258631706238 and the accuracy is 0.7909987568855286\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Specify multi-class logistic regression. \n",
    "model = Sequential()\n",
    "model.add(Dense(64,activation='selu'))\n",
    "model.add(Dense(128,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Specify the loss function, optimizer and metrics for training\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(),metrics=['accuracy'])\n",
    "# momentum and nesterov are hyperparameters for momentum mechanism to seed up training\n",
    "\n",
    "# Fit the model (this may take some time)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=2000)\n",
    "\n",
    "# Evaluate on the test set\n",
    "score = model.evaluate(X_test, y_test, batch_size=2000) # fill in\n",
    "print(\"On the test set: the loss is {} and the accuracy is {}\".format(score[0], score[1]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}