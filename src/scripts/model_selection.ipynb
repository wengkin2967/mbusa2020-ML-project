{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training set X: [[22.          2.          0.          3.         12.          0.46153846\n   3.          0.375       0.          0.        ]\n [14.          0.          1.          5.         13.          0.56521739\n   2.          0.33333333  0.          0.        ]]\nTraining set Y: [1 1]\n"
    }
   ],
   "source": [
    "train_set = pd.read_csv('../data/final/train_reconstructed.csv')\n",
    "\n",
    "X_train = train_set.iloc[:,:-1].values\n",
    "y_train = train_set['edge'].values\n",
    "\n",
    "print('Training set X: {}'.format(X_train[:2]))\n",
    "print('Training set Y: {}'.format(y_train[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test set X: [[ 9.          0.          1.          2.          6.          0.3\n   0.          0.          0.          0.        ]\n [12.          0.          0.          2.          8.          0.34782609\n   1.          0.14285714  0.          0.        ]]\nTest set Y: [0 1]\n"
    }
   ],
   "source": [
    "test_set = pd.read_csv('../data/final/dev-test.csv')\n",
    "\n",
    "X_test = test_set.iloc[:,:-1].values\n",
    "y_test = test_set['edge'].values\n",
    "\n",
    "print('Test set X: {}'.format(X_test[:2]))\n",
    "print('Test set Y: {}'.format(y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction : [1 1 1 1 1 1 1 1 1 1]\nAccuracy for train set: 0.5011557049800378\nAccuracy for dev set: 0.5\n"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "ds_clf = DummyClassifier(strategy=\"most_frequent\") # Define our model, set parameter strategy to 'most_frequent'\n",
    "ds_clf.fit(X_train, y_train) # Use model.fit to train with our dataset \n",
    "Y_predict = ds_clf.predict(X_test) # Use model.predict to make prediction\n",
    "print(\"Prediction :\", Y_predict[:10])\n",
    "print(\"Accuracy for train set:\", ds_clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set:\", ds_clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "alpha:0.10, acc_train:0.9593, acc_test:0.7641\nalpha:0.20, acc_train:0.9593, acc_test:0.7641\nalpha:0.30, acc_train:0.9593, acc_test:0.7641\nalpha:0.40, acc_train:0.9593, acc_test:0.7641\nalpha:0.50, acc_train:0.9593, acc_test:0.7641\nalpha:0.60, acc_train:0.9593, acc_test:0.7641\nalpha:0.70, acc_train:0.9593, acc_test:0.7641\nalpha:0.80, acc_train:0.9593, acc_test:0.7641\nalpha:0.90, acc_train:0.9593, acc_test:0.7641\nalpha:1.00, acc_train:0.9593, acc_test:0.7641\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "bnb_train_results = []\n",
    "bnb_test_results = []\n",
    "\n",
    "for a in alpha:\n",
    "    bnb = BernoulliNB(alpha=a)\n",
    "    bnb.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = bnb.score(X_train, y_train)\n",
    "    test_acc = bnb.score(X_test, y_test)\n",
    "    \n",
    "    print(\"alpha:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}\".format(a, train_acc, test_acc))\n",
    "    bnb_train_results.append(train_acc)\n",
    "    bnb_test_results.append(test_acc)\n",
    "    \n",
    "    # Prob of being one\n",
    "    Y_train_proba = bnb.predict_proba(X_test)\n",
    "    #print(\"Probabilities :\", Y_proba[:10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RF : depth:0.10, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7647\nRF : depth:0.20, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7647\nRF : depth:0.30, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7647\nRF : depth:0.40, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7647\nRF : depth:0.50, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\nRF : depth:0.60, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\nRF : depth:0.70, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\nRF : depth:0.80, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\nRF : depth:0.90, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\nRF : depth:1.00, acc_train:0.9069, acc_test:0.6741, AUC_train:0.9630, AUC_test:0.7646\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "mnb_train_results_acc = []\n",
    "mnb_test_results_acc = []\n",
    "mnb_train_results_auc = []\n",
    "mnb_test_results_auc = []\n",
    "\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(alpha=a)\n",
    "    mnb.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = mnb.score(X_train, y_train)\n",
    "    test_acc = mnb.score(X_test, y_test)\n",
    "    \n",
    "    # Prob of edge=1\n",
    "    y_train_proba = mnb.predict_proba(X_train)\n",
    "    y_test_proba = mnb.predict_proba(X_test)\n",
    "    \n",
    "    # get roc fpr and tpr\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "    auc_train = metrics.auc(fpr, tpr)\n",
    "    auc_test = metrics.auc(fpr1, tpr1)\n",
    "    print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                                                    train_acc, \n",
    "                                                                                                    test_acc,\n",
    "                                                                                                    auc_train,\n",
    "                                                                                                    auc_test))                 \n",
    "\n",
    "    mnb_train_results_acc.append(train_acc)\n",
    "    mnb_test_results_acc.append(test_acc)\n",
    "    mnb_train_results_auc.append(auc_train)\n",
    "    mnb_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GNB: acc_train:0.9518, acc_test:0.7875, AUC_train:0.9847, AUC_test:0.8104\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_train_results_acc = []\n",
    "gnb_test_results_acc = []\n",
    "gnb_train_results_auc = []\n",
    "gnb_test_results_auc = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "train_acc = gnb.score(X_train, y_train)\n",
    "test_acc = gnb.score(X_test, y_test)\n",
    "\n",
    "# Prob of edge=1\n",
    "y_train_proba = gnb.predict_proba(X_train)\n",
    "y_test_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "auc_train = metrics.auc(fpr, tpr)\n",
    "auc_test = metrics.auc(fpr1, tpr1)\n",
    "print(\"GNB: acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(train_acc, \n",
    "                                                                                         test_acc,\n",
    "                                                                                         auc_train,\n",
    "                                                                                         auc_test))                 \n",
    "\n",
    "gnb_train_results_acc.append(train_acc)\n",
    "gnb_test_results_acc.append(test_acc)\n",
    "gnb_train_results_auc.append(auc_train)\n",
    "gnb_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RF : depth:1.00, acc_train:0.9609, acc_test:0.7875, AUC_train:0.9817, AUC_test:0.8273\nRF : depth:2.00, acc_train:0.9606, acc_test:0.7875, AUC_train:0.9863, AUC_test:0.8286\nRF : depth:3.00, acc_train:0.9620, acc_test:0.7875, AUC_train:0.9887, AUC_test:0.8328\nRF : depth:4.00, acc_train:0.9631, acc_test:0.7875, AUC_train:0.9900, AUC_test:0.8324\nRF : depth:5.00, acc_train:0.9651, acc_test:0.7875, AUC_train:0.9909, AUC_test:0.8352\nRF : depth:6.00, acc_train:0.9663, acc_test:0.7875, AUC_train:0.9917, AUC_test:0.8368\nRF : depth:7.00, acc_train:0.9674, acc_test:0.7875, AUC_train:0.9925, AUC_test:0.8376\nRF : depth:8.00, acc_train:0.9688, acc_test:0.7875, AUC_train:0.9934, AUC_test:0.8367\nRF : depth:9.00, acc_train:0.9707, acc_test:0.7875, AUC_train:0.9944, AUC_test:0.8376\nRF : depth:10.00, acc_train:0.9727, acc_test:0.7875, AUC_train:0.9956, AUC_test:0.8390\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "depth = range(1,10+1)\n",
    "rf_train_results_acc = []\n",
    "rf_test_results_acc = []\n",
    "rf_train_results_auc = []\n",
    "rf_test_results_auc = []\n",
    "\n",
    "for d in depth:\n",
    "    rf = RandomForestClassifier(max_depth=d, n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_acc = rf.score(X_train,y_train)\n",
    "    # Prob of edge=1\n",
    "    y_train_proba = rf.predict_proba(X_train)\n",
    "    y_test_proba = rf.predict_proba(X_test)\n",
    "\n",
    "    # get roc fpr and tpr\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "    fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "    auc_train = metrics.auc(fpr, tpr)\n",
    "    auc_test = metrics.auc(fpr1, tpr1)\n",
    "    print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(d, \n",
    "                                                                                                    train_acc, \n",
    "                                                                                                    test_acc,\n",
    "                                                                                                    auc_train,\n",
    "                                                                                                    auc_test))                 \n",
    "\n",
    "    rf_train_results_acc.append(train_acc)\n",
    "    rf_test_results_acc.append(test_acc)\n",
    "    rf_train_results_auc.append(auc_train)\n",
    "    rf_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LR : acc_train:0.9727, acc_test:0.7875, AUC_train:0.9903, AUC_test:0.8398\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_train_results_acc = []\n",
    "lr_test_results_acc = []\n",
    "lr_train_results_auc = []\n",
    "lr_test_results_auc = []\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prob of edge=1\n",
    "y_train_proba = lr.predict_proba(X_train)\n",
    "y_test_proba = lr.predict_proba(X_test)\n",
    "\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba[:,1])\n",
    "fpr1, tpr1, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "auc_train = metrics.auc(fpr, tpr)\n",
    "auc_test = metrics.auc(fpr1, tpr1)\n",
    "print(\"LR : acc_train:{:.4f}, acc_test:{:.4f}, AUC_train:{:.4f}, AUC_test:{:.4f}\".format(train_acc, \n",
    "                                                                                         test_acc,\n",
    "                                                                                         auc_train,\n",
    "                                                                                         auc_test))                 \n",
    "\n",
    "lr_train_results_acc.append(train_acc)\n",
    "lr_test_results_acc.append(test_acc)\n",
    "lr_train_results_auc.append(auc_train)\n",
    "lr_test_results_auc.append(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GNB: alpha:----, acc_train:0.9518, acc_test:0.7875, AUC_test:0.8104\nMNB: alpha:1.00, acc_train:0.9069, acc_test:0.6741, AUC_test:0.7646\nRF : depth:1.00, acc_train:0.9672, acc_test:0.7830, AUC_test:0.8366\n"
    }
   ],
   "source": [
    "# use selected model and hyperparameter to calculate evaluation metrics: AUC, Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# GNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "train_acc = gnb.score(X_train, y_train)\n",
    "test_acc = gnb.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = gnb.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "# results\n",
    "print(\"GNB: alpha:----, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(\n",
    "                                                                                train_acc, \n",
    "                                                                                test_acc,\n",
    "                                                                                metrics.auc(fpr, tpr)))\n",
    "# MNB\n",
    "mnb = MultinomialNB(alpha=0.5)\n",
    "mnb.fit(X_train, y_train)\n",
    "train_acc = mnb.score(X_train, y_train)\n",
    "test_acc = mnb.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = mnb.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "# results\n",
    "print(\"MNB: alpha:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                            train_acc, \n",
    "                                                                            test_acc,\n",
    "                                                                            metrics.auc(fpr, tpr)))\n",
    "\n",
    "# random forest\n",
    "rf = RandomForestClassifier(max_depth=7, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "train_acc = rf.score(X_train,y_train)\n",
    "test_acc = rf.score(X_test, y_test)\n",
    "# Prob of edge=1\n",
    "y_test_proba = rf.predict_proba(X_test)\n",
    "# get roc fpr and tpr\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_proba[:,1])\n",
    "print(\"RF : depth:{:.2f}, acc_train:{:.4f}, acc_test:{:.4f}, AUC_test:{:.4f}\".format(a, \n",
    "                                                                                     train_acc, \n",
    "                                                                                     test_acc,\n",
    "                                                                                     metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training full model\n",
    "X_big = np.concatenate((X_train,X_test),0)\n",
    "y_big = np.concatenate((y_train,y_test),0)\n",
    "\n",
    "test_final = pd.read_csv('../data/final/test-final.csv')\n",
    "test_final = test_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [0.05542295 0.83438743 0.26441611 ... 0.10589638 0.1392115  0.77655458]\n"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "clf.fit(X_big, y_big)\n",
    "print(\"Probabilities :\", clf.predict_proba(test_final)[:,1])\n",
    "pred = clf.predict_proba(test_final)[:,1]\n",
    "# print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "# print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model.\n",
    "\n",
    "submission = {\n",
    "    'Id': range(1,len(pred)+1),\n",
    "    'Predicted': pred\n",
    "}\n",
    "\n",
    "submission_df = pd.DataFrame(data=submission)\n",
    "submission_df.to_csv('../data/final/sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}