{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training set X: [[22.          2.          0.          3.         12.          0.46153846\n   3.          0.375       0.          0.        ]\n [14.          0.          1.          5.         13.          0.56521739\n   2.          0.33333333  0.          0.        ]]\nTraining set Y: [1 1]\n"
    }
   ],
   "source": [
    "train_set = pd.read_csv('../data/final/train_reconstructed.csv')\n",
    "\n",
    "X_train = train_set.iloc[:,:-1].values\n",
    "y_train = train_set['edge'].values\n",
    "\n",
    "print('Training set X: {}'.format(X_train[:2]))\n",
    "print('Training set Y: {}'.format(y_train[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test set X: [[ 9.          0.          1.          2.          6.          0.3\n   0.          0.          0.          0.        ]\n [12.          0.          0.          2.          8.          0.34782609\n   1.          0.14285714  0.          0.        ]]\nTest set Y: [0 1]\n"
    }
   ],
   "source": [
    "test_set = pd.read_csv('../data/final/dev-test.csv')\n",
    "\n",
    "X_test = test_set.iloc[:,:-1].values\n",
    "y_test = test_set['edge'].values\n",
    "\n",
    "print('Test set X: {}'.format(X_test[:2]))\n",
    "print('Test set Y: {}'.format(y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction : [1 1 1 1 1 1 1 1 1 1]\nAccuracy for train set: 0.5013927576601671\nAccuracy for dev set: 0.5\n"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "ds_clf = DummyClassifier(strategy=\"most_frequent\") # Define our model, set parameter strategy to 'most_frequent'\n",
    "ds_clf.fit(X_train, y_train) # Use model.fit to train with our dataset \n",
    "Y_predict = ds_clf.predict(X_test) # Use model.predict to make prediction\n",
    "print(\"Prediction :\", Y_predict[:10])\n",
    "print(\"Accuracy for train set:\", ds_clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set:\", ds_clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [1.98339377e-05 1.99907224e-02 4.20573320e-04 5.90976879e-03\n 6.60444015e-01 6.60444015e-01 6.60444015e-01 6.60444015e-01\n 1.99907224e-02 4.50153082e-05]\nAccuracy for train set: 0.9596468176801387\nAccuracy for dev set:  0.7640772708590218\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "Y_proba = bnb.predict_proba(X_test) # Use model.predict to make prediction\n",
    "# Prob of being one\n",
    "print(\"Probabilities :\", Y_proba[:10,1])\n",
    "print(\"Accuracy for train set:\", bnb.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", bnb.score(X_test, y_test)) # Use model.score to evaluate our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [0.04991666 0.06684381 0.11988967 0.16334668 0.74430083 0.74430083\n 0.77337858 0.75021855 0.25037957 0.05300882]\nAccuracy for train set: 0.9613811951437431\nAccuracy for dev set:  0.8070283600493219\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 2 0.80\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Probabilities :\",  clf.predict_proba(X_test)[:10,1])\n",
    "print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for train set: 0.9612025017080991\nAccuracy for dev set:  0.7879161528976573\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0,max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.9129\nEpoch 2/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9556\nEpoch 3/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9607\nEpoch 4/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9622\nEpoch 5/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9630\nEpoch 6/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9633\nEpoch 7/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9636\nEpoch 8/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9635\nEpoch 9/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9640\nEpoch 10/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9639\nEpoch 11/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9640\nEpoch 12/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9641\nEpoch 13/30\n66/77 [========================>.....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9677/77 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9643\nEpoch 14/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9642\nEpoch 15/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9647\nEpoch 16/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9645\nEpoch 17/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9646\nEpoch 18/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9647\nEpoch 19/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9647\nEpoch 20/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9649\nEpoch 21/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9651\nEpoch 22/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9651\nEpoch 23/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9648\nEpoch 24/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9654\nEpoch 25/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9653\nEpoch 26/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9656\nEpoch 27/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9656\nEpoch 28/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9656\nEpoch 29/30\n77/77 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9657\nEpoch 30/30\n77/77 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9654\n4/4 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7922\nOn the test set: the loss is 0.6925538778305054 and the accuracy is 0.7922317981719971\n"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Specify multi-class logistic regression. \n",
    "model = Sequential()\n",
    "model.add(Dense(128,activation='tanh'))\n",
    "model.add(Dense(128,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Specify the loss function, optimizer and metrics for training\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(),metrics=['accuracy'])\n",
    "# momentum and nesterov are hyperparameters for momentum mechanism to seed up training\n",
    "\n",
    "# Fit the model (this may take some time)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=1250)\n",
    "\n",
    "# Evaluate on the test set\n",
    "score = model.evaluate(X_test, y_test, batch_size=1250) # fill in\n",
    "print(\"On the test set: the loss is {} and the accuracy is {}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training full model\n",
    "X_big = np.concatenate((X_train,X_test),0)\n",
    "y_big = np.concatenate((y_train,y_test),0)\n",
    "\n",
    "test_final = pd.read_csv('../data/final/test-final.csv')\n",
    "test_final = test_final.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Probabilities : [0.06548474 0.81886548 0.31918873 ... 0.13307536 0.2042267  0.73967939]\n"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,max_depth=2)\n",
    "clf.fit(X_big, y_big)\n",
    "print(\"Probabilities :\",  clf.predict_proba(test_final)[:,1])\n",
    "pred = clf.predict_proba(test_final)[:,1]\n",
    "# print(\"Accuracy for train set:\", clf.score(X_train,y_train))\n",
    "# print(\"Accuracy for dev set: \", clf.score(X_test, y_test)) # Use model.score to evaluate our model.\n",
    "\n",
    "submission = {\n",
    "    'Id': range(1,len(pred)+1),\n",
    "    'Predicted': pred\n",
    "}\n",
    "\n",
    "submission_df = pd.DataFrame(data=submission)\n",
    "submission_df.to_csv('../data/final/sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}